{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tL620UDQuJf-",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "238e22365a8606cb01f922f00c9ff18d",
     "grade": false,
     "grade_id": "cell-0f58b6936ef4f40a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Exercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7QOohJI8uJgE",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "922d6bbe754f3950bfb7b20132dfa66c",
     "grade": false,
     "grade_id": "cell-344a23109a194ec2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task Description\n",
    "\n",
    "The goal of this exercise is to model the relationship between weather observations and the prevalence of new weekly influenza infections.\n",
    "\n",
    "To investigate a potential relationship, we will use two datasets:\n",
    " * tri-daily weather reports from 2009 - 2021 of an unnamed city in Europe.\n",
    " * weekly reports on new influenza infections in the same city for the same time.\n",
    "\n",
    "In this exercise, you will \n",
    " * use `pandas` to read, prepare and transform data,\n",
    " * use `matplotlib` to visually analyse data,\n",
    "\n",
    "The data to be used can be found in: `~/shared/data/`. \n",
    "\n",
    "To complete this exercise, you will have to:\n",
    "* prepare the data, which (at minimum) involves the following:\n",
    "    - load and prepare the data\n",
    "    - handling missing values\n",
    "    - handling outliers\n",
    "    - temporal alignment of the two datasets\n",
    "* analyse the data:\n",
    "    - compare descriptive statistics\n",
    "    - visually investigate the raw data to gain an understanding of the data identify patterns, outliers etc.,\n",
    "    - look at the relationship between the variables of interest\n",
    "* model the relationship:\n",
    "    - fit a model that predicts new infections from weather observation data\n",
    "\n",
    "This notebook, totals 55 points (not in relation with the 65 points for the exam, but previously assigned like this for DOPP):\n",
    " - Task 1: 20 points\n",
    " - Task 2: 15 points\n",
    " - Task 3: 10 points\n",
    " - Task 4: 5 points\n",
    " - Task 5: 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5FCqq4N2uJgD",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13771d1ccc2bb316fe44a64bdd8372c9",
     "grade": false,
     "grade_id": "cell-16f055fc7f1e7564",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!! \n",
    "# Note: The only imports allowed are Python's standard library, pandas, numpy, scipy, matplotlib, seaborn and scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pickle\n",
    "import typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tPTXx31BuJgH",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f43babe36e657e7b9bdcd7465bfca64b",
     "grade": false,
     "grade_id": "cell-ee1735e45c45a5d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 1: Load Data (20 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "g9hckbneuJgI",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7599ddaaf69668f69899c40a956631a5",
     "grade": false,
     "grade_id": "cell-d579b789cc8242e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1.1: Weather observations\n",
    "\n",
    "As a first step, implement the method `load_weather_data()`, which should read all individual (yearly) datasets from the csv files in `data\\weather\\` into a single `pd.DataFrame` and return it. \n",
    "\n",
    "- make sure that you load all the data (2009-2021, 13 years)\n",
    "- split the tri-daily and daily data (tri-daily data has _7h, _14h, and _19h suffixes for column headers), and convert the tri-daily data from a wide to a long format (use pandas' [wide_to_long](https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html) or [melt](https://pandas.pydata.org/docs/reference/api/pandas.melt.html#pandas.melt) functions). Introduce a new `hours` column which's values should be taken from the column suffixes.\n",
    "- make sure all columns are appropriately typed (numeric values -> float, countables, i.e. days -> int, etc.)! Especially the `date` column! See datetime and [`pandas.Timestamp`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html)!\n",
    "- from the `date` column create `year`, `month`, `week`, `day` columns, where `week` contains the week number of the date. Use Pandas built-in datetime handling features.\n",
    "- from the wide to long transform, you should have an `hour` column with the 7, 14, or 19 hours values.\n",
    "- create a `MultiIndex` from the date columns with the following hierarchy: `year` - `month` - `week` - `day` - `hour` (make sure to label them accordingly)\n",
    "\n",
    "**Hints:**\n",
    " \n",
    " - LOOK at the data in the original files\n",
    " - It is advisable not to append each data set individually, but to read each data frame, store it into a list and  combine them once at the end.\n",
    " - Note that for the `precip` data column you will get an unexpected (object) datatype. For this task it is ok to leave it like that, it is due to special values, see next chapters!\n",
    " - Your resulting data frame should look as follows:\n",
    "\n",
    "![Weather data frame example](weather_data_dataframe_sample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PQ6VwrxR47jF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87f00502937706205384e5095ef19c2c",
     "grade": false,
     "grade_id": "cell-a96c14d36ff029a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!! \n",
    "data_path = os.path.join(os.environ[\"HOME\"], \"shared\", \"194.192-2025W\", \"data\")\n",
    "weather_data_path = os.path.join(data_path, 'weather')\n",
    "influenza_data_path = os.path.join(data_path, 'influenza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "n0MM-kr-m3Ax",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21019dc19a2de51b21fe04e3e485abfa",
     "grade": false,
     "grade_id": "cell-6c7dab00d63ebef3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def load_weather_data(weather_data_path:str) -> typing.Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\" \n    Load all weather data files and combine them into a single Pandas DataFrame.\n    Split the tri-daily data from the daily data.\n    For the tri-daily data create a new hour column using the indicated hour in the column names.\n    Add a week column and a hierarchical index (year, month, week, day, hour).\n    For the daily-only data also add a hierarchical index (year, month, week, day).\n    \n    Parameters\n    --------\n    weather_data_path: path to directory containing weather data CSV files\n    \n    Returns\n    --------\n    weather_data: data frame containing the tri-daily (hours) weather data\n    weather_data_daily: data frame containing the daily weather data (e.g. precip, precipType, etc.)\n    \"\"\"\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n    \n    return weather_data, weather_data_daily",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import builtins\n",
    "builtins.assert_ = lambda cond, msg=None: None\n",
    "\n",
    "def load_weather_data(weather_data_path:str) -> typing.Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\" \n",
    "    Load all weather data files and combine them into a single Pandas DataFrame.\n",
    "    Split the tri-daily data from the daily data.\n",
    "    For the tri-daily data create a new hour column using the indicated hour in the column names.\n",
    "    Add a week column and a hierarchical index (year, month, week, day, hour).\n",
    "    For the daily-only data also add a hierarchical index (year, month, week, day).\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    weather_data_path: path to directory containing weather data CSV files\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    weather_data: data frame containing the tri-daily (hours) weather data\n",
    "    weather_data_daily: data frame containing the daily weather data (e.g. precip, precipType, etc.)\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    dirs = os.listdir(weather_data_path)\n",
    "    print(dirs)\n",
    "    dfs = []\n",
    "    for dir in dirs:\n",
    "        if dir.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(weather_data_path, dir), sep = ';')\n",
    "            dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'], format = '%d.%m.%Y')\n",
    "\n",
    "    df = pd.wide_to_long(df, stubnames = ['airPressure','skyCover','temp','hum','windDir','windBeauf'], i = 'date', j = 'hour', sep='_', suffix='\\\\d+h').reset_index()\n",
    "    df['hour'] = df['hour'].str.replace('h','')\n",
    "\n",
    "    df['week'] = df['date'].apply(lambda x: pd.Timestamp(x).week)\n",
    "\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    \n",
    "    cols = ['year','month','day','week','airPressure','skyCover','temp','hum','windBeauf', 'hour']\n",
    "    df[cols] = df[cols].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "    weather_data = df.filter(items = ['date','hour','airPressure','skyCover','temp','hum','week','year','day','month', 'windDir','windBeauf'])\n",
    "    weather_data_daily = df.filter(items = ['date','precip','precipType','week','year','day','month'])\n",
    "\n",
    "    weather_data = weather_data.set_index(keys = ['year','month','week','day','hour'])\n",
    "    weather_data_daily = weather_data_daily.set_index(keys = ['year','month','day','week'])\n",
    "    \n",
    "    return weather_data, weather_data_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "deletable": false,
    "editable": false,
    "id": "vfY3gTFZtVLo",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad8b6e2e8d67617f2b7b3441dee28004",
     "grade": false,
     "grade_id": "cell-f91fef9d5c18b362",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "339c3ef8-d3e8-4601-89e6-bd5f37f2281f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather_daily_2010.csv', 'weather_daily_2019.csv', 'descriptions.txt', 'weather_daily_2013.csv', 'weather_daily_2021.csv', 'weather_daily_2011.csv', 'weather_daily_2012.csv', 'weather_daily_2009.csv', 'weather_daily_2014.csv', 'weather_daily_2018.csv', 'weather_daily_2016.csv', 'weather_daily_2020.csv', 'weather_daily_2017.csv', 'weather_daily_2015.csv', '.ipynb_checkpoints']\n",
      "hourly weather data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>airPressure</th>\n",
       "      <th>skyCover</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windDir</th>\n",
       "      <th>windBeauf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2010</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">53</th>\n",
       "      <th>1</th>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>966.4</td>\n",
       "      <td>10</td>\n",
       "      <td>4.1</td>\n",
       "      <td>94</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>977.6</td>\n",
       "      <td>10</td>\n",
       "      <td>1.8</td>\n",
       "      <td>92</td>\n",
       "      <td>W</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>992.6</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>69</td>\n",
       "      <td>W</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>4</th>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>993.6</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>79</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>986.8</td>\n",
       "      <td>10</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>86</td>\n",
       "      <td>SE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               date  airPressure  skyCover  temp  hum windDir  \\\n",
       "year month week day hour                                                        \n",
       "2010 1     53   1   7    2010-01-01        966.4        10   4.1   94       W   \n",
       "                2   7    2010-01-02        977.6        10   1.8   92       W   \n",
       "                3   7    2010-01-03        992.6         4  -2.7   69       W   \n",
       "           1    4   7    2010-01-04        993.6         9  -1.8   79       S   \n",
       "                5   7    2010-01-05        986.8        10  -3.0   86      SE   \n",
       "\n",
       "                          windBeauf  \n",
       "year month week day hour             \n",
       "2010 1     53   1   7             1  \n",
       "                2   7             3  \n",
       "                3   7             4  \n",
       "           1    4   7             2  \n",
       "                5   7             2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "daily weather data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>precip</th>\n",
       "      <th>precipType</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2010</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <th>53</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>3.6</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>53</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>3.9</td>\n",
       "      <td>rain and snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>53</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>0.4</td>\n",
       "      <td>snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>6.2</td>\n",
       "      <td>snow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date precip     precipType\n",
       "year month day week                                 \n",
       "2010 1     1   53   2010-01-01    3.6           rain\n",
       "           2   53   2010-01-02    3.9  rain and snow\n",
       "           3   53   2010-01-03    0.4           snow\n",
       "           4   1    2010-01-04      0            NaN\n",
       "           5   1    2010-01-05    6.2           snow"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!! \n",
    "weather_data, daily_weather_data = load_weather_data(weather_data_path)\n",
    "# print first couple of rows:\n",
    "print('hourly weather data:')\n",
    "display(weather_data.head())\n",
    "print('\\ndaily weather data:')\n",
    "display(daily_weather_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBlDg_afwUwy",
    "outputId": "0f1e519d-c003-4ba8-fcab-1751e1111036",
    "revert": "# use this cell to inspect the data.\n\nprint(f\"Data dimensions are: {weather_data.shape[0]} rows and {weather_data.shape[1]} columns\")\nprint(f\"\\nindex types are: \\n-----------------\\n{weather_data.index.dtypes}\")\nprint(f\"\\ncolumn types are: \\n-----------------\\n{weather_data.dtypes}\")\n\nprint(f\"\\nFor daily data: \\nData dimensions are: {daily_weather_data.shape[0]} rows and {daily_weather_data.shape[1]} columns\")\nprint(f\"\\nindex types are: \\n-----------------\\n{daily_weather_data.index.dtypes}\")\nprint(f\"\\ncolumn types are: \\n-----------------\\n{daily_weather_data.dtypes}\")\n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions are: 14244 rows and 7 columns\n",
      "\n",
      "index types are: \n",
      "-----------------\n",
      "year     int32\n",
      "month    int32\n",
      "week     int64\n",
      "day      int32\n",
      "hour     int64\n",
      "dtype: object\n",
      "\n",
      "column types are: \n",
      "-----------------\n",
      "date           datetime64[ns]\n",
      "airPressure           float64\n",
      "skyCover                int64\n",
      "temp                  float64\n",
      "hum                     int64\n",
      "windDir                object\n",
      "windBeauf               int64\n",
      "dtype: object\n",
      "\n",
      "For daily data: \n",
      "Data dimensions are: 14244 rows and 3 columns\n",
      "\n",
      "index types are: \n",
      "-----------------\n",
      "year     int32\n",
      "month    int32\n",
      "day      int32\n",
      "week     int64\n",
      "dtype: object\n",
      "\n",
      "column types are: \n",
      "-----------------\n",
      "date          datetime64[ns]\n",
      "precip                object\n",
      "precipType            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# use this cell to inspect the data.\n",
    "\n",
    "print(f\"Data dimensions are: {weather_data.shape[0]} rows and {weather_data.shape[1]} columns\")\n",
    "print(f\"\\nindex types are: \\n-----------------\\n{weather_data.index.dtypes}\")\n",
    "print(f\"\\ncolumn types are: \\n-----------------\\n{weather_data.dtypes}\")\n",
    "\n",
    "print(f\"\\nFor daily data: \\nData dimensions are: {daily_weather_data.shape[0]} rows and {daily_weather_data.shape[1]} columns\")\n",
    "print(f\"\\nindex types are: \\n-----------------\\n{daily_weather_data.index.dtypes}\")\n",
    "print(f\"\\ncolumn types are: \\n-----------------\\n{daily_weather_data.dtypes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "j-DydORPzWH3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "995ec79083f7028ae26ca357004f4fae",
     "grade": false,
     "grade_id": "cell-b67cb45d509d8ebc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Tests\n",
    "Optional but recommended!\n",
    "Check if the loading of the data was successful using some assertions.\n",
    "The points will automatically assigned by the hidden test, try to make sure that you covered all required points from above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "U6XXR5hbzRxF",
    "revert": "# use this cell to create your own tests. best case: create a test for each requirement above!\n\n# Note: you can add new cells also for the other tasks to add your own tests. \n# But NEVER COPY an existing cell, since this can break the autograding!"
   },
   "outputs": [],
   "source": [
    "# use this cell to create your own tests. best case: create a test for each requirement above!\n",
    "\n",
    "# Note: you can add new cells also for the other tasks to add your own tests. \n",
    "# But NEVER COPY an existing cell, since this can break the autograding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WTCWDGxnzU6s",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a25ecbef23a2c4e3f59ff1549e1773b",
     "grade": true,
     "grade_id": "cell-873e9bd65e642c4d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!! \n",
    "# TESTS: dimensions should be like this:\n",
    "assert weather_data.shape[0] == 14244 # 4748\n",
    "assert weather_data.shape[1] >= 7 # 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "teARlPDFuJgL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93f8c6dddc39d94c97ac84d6966e6fc3",
     "grade": true,
     "grade_id": "cell-3730b87b3eaced00",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests for grading DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2YemAI-6uJgL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60ea492d166cd20daa4da103de7923df",
     "grade": true,
     "grade_id": "cell-504e050c5ee55320",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_Lwe8oNT4JUh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7910cae70ee2af234d8ce67b6d8bdbe0",
     "grade": true,
     "grade_id": "cell-5dfe6663194550b3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "jAS61ONpuJgL",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "149572a55bafe6dbbd73d1532540e4d6",
     "grade": false,
     "grade_id": "cell-10963c38d6f9376b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Question\n",
    "Which combination of year+month has the highest number of entries?\n",
    "- Implement the function below to find the answer!\n",
    "- Find the respective entry/entries using pandas!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "id": "6WnaJzVm-1cJ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31f0ed33f63c8f3cf510ab6374714ace",
     "grade": false,
     "grade_id": "cell-182255c90bc1dc1c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def get_year_month_highest_entries(data_frame:pd.DataFrame):\n    year = 0\n    month = 0\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return year, month",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_year_month_highest_entries(data_frame:pd.DataFrame):\n",
    "    year = 0\n",
    "    month = 0\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    df = data_frame.copy().reset_index().groupby(by = ['year','month'])\n",
    "\n",
    "    out = None\n",
    "    maxi = 0\n",
    "    for x,y in df:\n",
    "        num = y.count().max()\n",
    "        if num > maxi:\n",
    "            maxi = num\n",
    "            out = x\n",
    "\n",
    "    year, month = out\n",
    "\n",
    "    return year, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "Ru1m3q0D-3EX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76819a2922454de1afb8fa446e95e79f",
     "grade": false,
     "grade_id": "cell-74c52563439f6402",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "42ccb99a-7b55-4a74-eecd-1ad8a3a54554",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 1, of year 2009 has the highest number of entries!\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!!\n",
    "high_num_year, high_num_month = get_year_month_highest_entries(weather_data)\n",
    "print(f\"Month {high_num_month}, of year {high_num_year} has the highest number of entries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "AWQ7OK_vuJgN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c2116322b93d94f8d122c67e7c3d5d1",
     "grade": true,
     "grade_id": "cell-ab2a4b58923b3d03",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "SLeir2rluJgN",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d79ed485c03e6d1acc511ce417e7cd5f",
     "grade": false,
     "grade_id": "cell-49fb8721ee9b7bfa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 1.2: Influenza infections\n",
    "\n",
    "Load and prepare the second dataset (`data/influenza/influenza.csv`), which contains the number of new influenza infections on a weekly basis.\n",
    "- Stack all seasonal data files into one dataframe\n",
    "- Extract a correct `year` and `week` column from the `Season Week` column, see `data/influenza/descriptions.txt` for details.\n",
    "- For each entry, extract the year based on the season and month values\n",
    "- Create a `MultiIndex` from the `year` and `week` columns\n",
    "- Rename column containing influenza cases to `weekly_infections`\n",
    "- Make sure that all columns have appropriate types\n",
    "- Remove rows with missing infection counts\n",
    "- Your resulting data frame should look as follows:\n",
    "\n",
    "![Example data frame](influenza_data_dataframe_sample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "id": "9iy60dbjOwxw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "854a62a18559bbf02cc12797e35a3ff3",
     "grade": false,
     "grade_id": "cell-fe3966bcb8510be9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def load_influenza_data() -> pd.DataFrame:\n    \"\"\" \n    Load the influenza data from the files into a pndas dataframe\n    \n    Returns\n    --------\n    influenza_data: data frame containing the influenza data\n    \"\"\"\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n    \n    return influenza_data",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_influenza_data() -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Load the influenza data from the files into a pndas dataframe\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    influenza_data: data frame containing the influenza data\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_col(row):\n",
    "        years = row.split('_')[0]\n",
    "        week = row.split('_')[1]\n",
    "\n",
    "        year1 = years.split('/')[0]\n",
    "        year2 = years.split('/')[1]\n",
    "\n",
    "        if int(week) > 25:\n",
    "            return pd.Series([year1, week])\n",
    "        else:\n",
    "            return pd.Series([year2, week])\n",
    "    \n",
    "    dirs = os.listdir(influenza_data_path)\n",
    "    dfs = []\n",
    "    for dir in dirs:\n",
    "        if dir.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(influenza_data_path, dir))\n",
    "            dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    df[['year', 'week']] = df['Season Week'].apply(extract_col)\n",
    "\n",
    "    df = df.drop(columns = ['Season Week', 'Margin'])\n",
    "\n",
    "    df = df.rename(columns = {'New Cases': 'weekly_infections'})\n",
    "\n",
    "\n",
    "    df['weekly_infections'] = df['weekly_infections'].replace('-', np.nan)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    cols = ['weekly_infections','year','week']\n",
    "    df[cols] = df[cols].apply(pd.to_numeric)\n",
    "\n",
    "    influenza_data = df.set_index(keys = ['year','week'])\n",
    "    \n",
    "    return influenza_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "deletable": false,
    "editable": false,
    "id": "Kf32BXK0TREM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ea26550fc1bcc2ea6ab44e8fc8322b9",
     "grade": false,
     "grade_id": "cell-3e20d32bce359015",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "424f702d-7952-4793-df56-8c19f58e0614",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>weekly_infections</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">2019</th>\n",
       "      <th>52</th>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           weekly_infections\n",
       "year week                   \n",
       "2019 52                 3500\n",
       "     51                 5900\n",
       "     50                 6000\n",
       "     49                 5900\n",
       "     48                 5500\n",
       "...                      ...\n",
       "     10                 8900\n",
       "     11                 6200\n",
       "     12                 5500\n",
       "     13                 3900\n",
       "     14                 3300\n",
       "\n",
       "[310 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!! \n",
    "data_influenza = load_influenza_data()\n",
    "display(data_influenza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpThKHTdVc_0",
    "outputId": "068ccb44-9940-4cff-a12e-88aeaaecd38d",
    "revert": "# use this cell to inspect the data.\n\nprint(f\"Data dimensions are: {data_influenza.shape[0]} rows and {data_influenza.shape[1]} columns\")\nprint(f\"\\nindex types are: \\n-----------------\\n{data_influenza.index.dtypes}\")\nprint(f\"\\ncolumn types are: \\n-----------------\\n{data_influenza.dtypes}\")"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions are: 310 rows and 1 columns\n",
      "\n",
      "index types are: \n",
      "-----------------\n",
      "year    int64\n",
      "week    int64\n",
      "dtype: object\n",
      "\n",
      "column types are: \n",
      "-----------------\n",
      "weekly_infections    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# use this cell to inspect the data.\n",
    "\n",
    "print(f\"Data dimensions are: {data_influenza.shape[0]} rows and {data_influenza.shape[1]} columns\")\n",
    "print(f\"\\nindex types are: \\n-----------------\\n{data_influenza.index.dtypes}\")\n",
    "print(f\"\\ncolumn types are: \\n-----------------\\n{data_influenza.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7demfS_RYKRy",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f931f581170a3185980fa44a9005e3f8",
     "grade": false,
     "grade_id": "cell-6cd57bacaefac1d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Tests\n",
    "Optional but recommended!\n",
    "Check if the loading of the data was successful using some assertions.\n",
    "The points will automatically be assigned by the hidden test, try to make sure that you covered all required points from above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "C0-EDr95XrIS",
    "revert": "# use this cell to create your own tests\n"
   },
   "outputs": [],
   "source": [
    "# use this cell to create your own tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "58GvQuH5WuE3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10be5c3abe791fd13c12634b772471e7",
     "grade": true,
     "grade_id": "cell-9795f79f67facf65",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tests DO NOT MODIFY OR COPY THIS CELL!! \n",
    "# final dimensions should be like this:\n",
    "assert data_influenza.shape == (310, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eXA1zkebXWPw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c61dbe022dd17bbc50938a9845a57964",
     "grade": true,
     "grade_id": "cell-1d79c03b58eebd2f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests, DO NOT MODIFY OR COPY THIS CELL!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OO3KT68MuJgP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23898d11a0b64171a16261ee458b94dc",
     "grade": true,
     "grade_id": "cell-192a6ebaf4390fd0",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests, DO NOT MODIFY OR COPY THIS CELL!! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "63ZWOwOtuJgQ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10edd466d18c1b535b12712a6c3e95b0",
     "grade": false,
     "grade_id": "cell-3660c76491f9a4e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Question\n",
    "Which combination of year+week shows the highest number of infections? \n",
    "- Implement the function below to return the result!\n",
    "- You should find the respective entry/entries using pandas!\n",
    "- Return the first answer if there is more than one combination fulfilling these criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "RQn_De0vY5hm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8eb3125045c23a32583fd120b2ced59",
     "grade": false,
     "grade_id": "cell-d43a00421004df88",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def get_year_week_most_infections(data_frame:pd.DataFrame\n                                  ) -> typing.Tuple[int, int]:\n    year = 0\n    week = 0\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return year, week",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_year_week_most_infections(data_frame:pd.DataFrame\n",
    "                                  ) -> typing.Tuple[int, int]:\n",
    "    year = 0\n",
    "    week = 0\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    year, week = data_frame.copy().reset_index().groupby(by = ['year','week'])['weekly_infections'].max().idxmax()\n",
    "\n",
    "    return year, week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "ticGgJUuYow2",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "814f3f2305743c724fd3b616d8342097",
     "grade": false,
     "grade_id": "cell-66fa367aa2a8b5bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c589c4ce-6955-4842-be0e-4b46e6b3bff3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!! \n",
    "high_num_year, high_num_week = get_year_week_most_infections(data_influenza)\n",
    "print(f\"Week {high_num_week}, of year {high_num_year} has the highest number of infections!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YOiiRIXqMRK_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "682036f334bd749db39517471f437dcf",
     "grade": true,
     "grade_id": "cell-b13dd3d749592948",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests, DO NOT MODIFY OR COPY THIS CELL!! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "LInDG8s0uJgS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e5e9c00d7ee3b9fb89ec48f9a0539e6",
     "grade": false,
     "grade_id": "cell-978643b867edf57e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 2: Handling Missing Values (15 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "z8RQwVU-uJgS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f35f4fa154cb470e9bce80fadc8e562",
     "grade": false,
     "grade_id": "cell-690270a0d9b477d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "If you take a closer look at the data, you will notice that a few of the observations are missing.\n",
    "\n",
    "There is a wide range of standard strategies to deal with such missing values, including:\n",
    "\n",
    "- row deletion\n",
    "- substitution methods (e.g., replace with mean or median)\n",
    "- hot-/cold-deck methods (impute from a randomly selected similar record)\n",
    "- regression methods\n",
    "\n",
    "To decide which strategy is appropriate, it is essential to investigate the mechanism that led to the missing values to find out whether the missing data is missing completely at random, missing at random, or missing not at random. \n",
    "\n",
    " - **MCAR** (Missing Completely At Random) means that there is no relationship between the missingness of the data and any of the values.\n",
    " - **MAR** (Missing At Random) means that there is a systematic relationship between the propensity of missing values and the observed data, but not the missing data.\n",
    " - **MNAR** (Missing Not At Random) means that there is a systematic relationship between the propensity of a value to be missing and its values. \n",
    " \n",
    "\n",
    "_______\n",
    "\n",
    "You talked to the meteorologists who compiled the data to find out more about what mechanisms may have caused the missing values: \n",
    "\n",
    "1. They told you that they do not know why some of the temperature (`temp`) and pressure (`airPressure`) readings are missing. They suspect a problem with the IT infrastructure. In any case, the propensity of temperature and pressure values to be missing does not have anything to do with the weather itself.\n",
    "\n",
    "2. For wind intensity values of 0, the wind direction is not provided (for obvious reasons). \n",
    "\n",
    "Check the plausibility of these hypotheses in the data, consider the implications, and devise appropriate strategies to deal with the various missing values.\n",
    "\n",
    "- Handle missing values for the following columns: `temp`, `airPressure`, `windDir`\n",
    "\n",
    "To implement your strategy, you can use a range of standard mechanisms provided by Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wVhPFbEXLfXS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f0baaaff371bab27dab290c59106e56",
     "grade": false,
     "grade_id": "cell-b3050272e3cb06e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Visualize some data\n",
    "Plot temperature (temp) and air pressure (airPressure) as a function of time for the weather data.\n",
    "Additionally plot the average weekly sky coverage over all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "deletable": false,
    "id": "Howc20nk3_fq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ce510f7bab618dc7bf738545d1f61b3",
     "grade": false,
     "grade_id": "cell-8b05623ec9da853a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "76dd9548-5671-4b28-a55b-7412cc281e30",
    "revert": "# plot the temperature \n\n# YOUR CODE HERE\nraise NotImplementedError()\n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the temperature \n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "df = weather_data.copy().sort_values(by = 'date')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['date'], df['temp'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "deletable": false,
    "id": "1MES-k_TMm1M",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e515d6907bc2d155eea2ec69332a62e",
     "grade": false,
     "grade_id": "cell-19e4f9571a256db7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "229daa37-f83a-4226-9a07-0546c47243c3",
    "revert": "# plot the temperature \n\n# YOUR CODE HERE\nraise NotImplementedError()",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the temperature \n",
    "\n",
    "# YOUR CODE HERE\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['date'], df['airPressure'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "deletable": false,
    "id": "yjyOUf6PMp8A",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d1262a50923410ac6ebc3b8f3ce6c3e",
     "grade": false,
     "grade_id": "cell-f2ffd361a8954596",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "af9665e2-1c4f-41af-b562-144c66ae2e2f",
    "revert": "# plot the sky coverage \n\n# YOUR CODE HERE\nraise NotImplementedError()",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the sky coverage \n",
    "\n",
    "# Additionally plot the average weekly sky coverage over all years.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "df = df.copy().reset_index().groupby('year')['skyCover'].mean()\n",
    "\n",
    "df.plot(kind = 'line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zWDut28JvXps",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d2064cf4b42c6eb77e9f60dcd3d5578",
     "grade": false,
     "grade_id": "cell-4f139bb699bf2395",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 2.1: Missing values for temperature and air pressure\n",
    "Find and visualize missing values for `temp` and `airPressure` columns in the `weather_data` data frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "82ynpetztgg6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb0185041c46d2c30b287d5e821e8d9d",
     "grade": false,
     "grade_id": "cell-12000995593c8b51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Data inspection\n",
    "First, let's visualize the missing data to get a better feel for what is happening.\n",
    "- Implement the `get_data_around_missing` function below to extract and return a dataframe that only contains rows around missing (`isna`, `isnull`) values for the column indicated by `column`.\n",
    "- First find missing values in the specified column\n",
    "- For each missing value, create a dataframe that contain only rows with a date +- `delta_days` from the date of the missing value.\n",
    "- Put the dataframes into `df_list` and return them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Kfp3EMMHvXSy",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dac805d811931270bb0aced1ba910c36",
     "grade": false,
     "grade_id": "cell-5fefb72fda74f2cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def get_data_around_missing(df:pd.DataFrame, column:str, \n                            delta_days:int=2) -> typing.List[pd.DataFrame]:\n    \"\"\" \n    Build a list of dataframes containing missing values indicated by column. \n    Each dataframe contains rows around a missing (isna)\n    value in column, within a date of +- delta_days.\n\n    Parameters\n    --------\n    df: dataframe containing the missing values\n    column: the column to look for missing values\n    delta_days: the number of days +-around the date of the missing values to keep in the returned data frames\n    \n    Returns\n    --------\n    df_list: list of dataframes with some missing data\n    \"\"\"\n    # TODO better description\n    # check out datetime.timedelta! \n    df_list = []\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return df_list\n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_around_missing(df:pd.DataFrame, column:str, \n",
    "                            delta_days:int=2) -> typing.List[pd.DataFrame]:\n",
    "    \"\"\" \n",
    "    Build a list of dataframes containing missing values indicated by column. \n",
    "    Each dataframe contains rows around a missing (isna)\n",
    "    value in column, within a date of +- delta_days.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    df: dataframe containing the missing values\n",
    "    column: the column to look for missing values\n",
    "    delta_days: the number of days +-around the date of the missing values to keep in the returned data frames\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    df_list: list of dataframes with some missing data\n",
    "    \"\"\"\n",
    "    # TODO better description\n",
    "    # check out datetime.timedelta! \n",
    "    df_list = []\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    from pandas.tseries.offsets import DateOffset\n",
    "    df_temp = df.reset_index().sort_values(by = ['year','month','week', 'day','hour'])\n",
    "\n",
    "    nan_rows = df_temp[df_temp[column].isna()]\n",
    "\n",
    "    for index, data in nan_rows.iterrows():\n",
    "        date = data['date']\n",
    "        hour = data['hour']\n",
    "\n",
    "        start_date = date - DateOffset(days=delta_days)\n",
    "        end_date = date + DateOffset(days=delta_days)\n",
    "\n",
    "        select_df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "        df_list.append(select_df)\n",
    "    \n",
    "    \n",
    "    return df_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1qn4V_L2wRYN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "457fc8756f67db6fb238f1f17fc74804",
     "grade": false,
     "grade_id": "cell-5f634a8ba115b51c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!! \n",
    "missing_temp_df_list = get_data_around_missing(weather_data, 'temp')\n",
    "missing_airPressure_df_list = get_data_around_missing(weather_data, 'airPressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "k7-aveSJw6uK",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe1526b01bb30d479861760342572425",
     "grade": true,
     "grade_id": "cell-7216949db55134b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "946252dd-366d-42f9-91d2-9a5fb2dd4a28",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tests, DO NOT MODIFY OR COPY THIS CELL!! \n",
    "print(len(missing_temp_df_list))\n",
    "print(len(missing_airPressure_df_list))\n",
    "\n",
    "assert 150 < len(missing_temp_df_list) < 250, \"There should be between 150 and 150 missing values in temp!\"\n",
    "assert 150 < len(missing_airPressure_df_list) < 250, \"There should be between 150 and 250 missing values in airPressure!\"\n",
    "\n",
    "assert all([isinstance(cur_el, pd.DataFrame) for cur_el in missing_temp_df_list])\n",
    "assert all([isinstance(cur_el, pd.DataFrame) for cur_el in missing_airPressure_df_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZsGVUYl9dGR0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1350d9022d49387174b81929eb0de856",
     "grade": true,
     "grade_id": "cell-52bb9dab3bbe03d2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests, DO NOT MODIFY OR COPY THIS CELL!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "T7Fim4rb2hcq",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "315f831c0d2b734d714f3ff6360611e2",
     "grade": false,
     "grade_id": "cell-12930900fdfb2d43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "In order to be able to see the data, complete the function `plot_value_series` to plot a timeseries of a dataframe identified by `column`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Ixp8dBzE16Eq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2fa4e02af23e6ee7e3a002a1778e323",
     "grade": false,
     "grade_id": "cell-4e32e7a457a00b6d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def plot_value_series(df:pd.DataFrame, column:str) -> None:\n    \"\"\" \n    Plot the values in column in data frame df\n    \"\"\"\n    # YOUR CODE HERE\n    raise NotImplementedError()\n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_value_series(df:pd.DataFrame, column:str) -> None:\n",
    "    \"\"\" \n",
    "    Plot the values in column in data frame df\n",
    "    \"\"\"\n",
    "    df_temp = df.copy().reset_index().sort_values(by = ['year','month','week', 'day','hour'])\n",
    "\n",
    "    df_temp['timed_date'] = pd.to_datetime(df_temp['date']) + pd.to_timedelta(df_temp['hour'], unit='h')\n",
    "    \n",
    "    df_temp.plot(x = 'timed_date', y= column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "idcSN6Ao3SwL",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a80b1c0a0839bd905466e0b3206fc52f",
     "grade": false,
     "grade_id": "cell-d033128e008ba2eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Now we use the function to plot a missing value for `temp` and `airPressure`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "deletable": false,
    "editable": false,
    "id": "AfszM1iSwd92",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f12bf25253315dbedcedeb04781df01",
     "grade": false,
     "grade_id": "cell-8e62db86afb7c106",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "8931e5b1-3539-4662-e0f1-7dcaca842b63",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tests,  DO NOT MODIFY OR COPY THIS CELL!! \n",
    "plot_value_series(missing_temp_df_list[0], 'temp')\n",
    "plot_value_series(missing_airPressure_df_list[0], 'airPressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "deletable": false,
    "editable": false,
    "id": "TAOf70dGw6kv",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5949c82ef630c01d88e2fa38a54f390",
     "grade": true,
     "grade_id": "cell-8afe8042639c2549",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "eab7b0ac-35a6-4ffb-9dc0-3db9c2d52cec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests, DO NOT MODIFY OR COPY THIS CELL!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TE7XATXI4DPx",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5d591fa31bc23f6ed86dd2abe3b895d",
     "grade": false,
     "grade_id": "cell-dbc572378af62630",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Handle missing temperature values\n",
    "Use the plots above and the information that was given to us by the meterologist to decide on a suitable strategy to fix the missing values.\n",
    "\n",
    "- Implement the function below to get rid of the missing values for temperature (`temp`).\n",
    "- Choose an appropriate strategy to fill in the misssing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "bt2TRYhx39pP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea0a737cee0572122fee40f6331b14e1",
     "grade": false,
     "grade_id": "cell-61401abddea4b7a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def handle_missing_temp_values(df:pd.DataFrame) -> pd.DataFrame:\n    \"\"\" \n    Handle missing temperature values appropriately!\n\n    Parameters\n    --------\n    df: dataframe containing the missing values\n    \n    Returns\n    --------\n    df_ret: dataframe with fixed values\n    \"\"\"\n    df_ret = df.copy()\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return df_ret",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_missing_temp_values(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Handle missing temperature values appropriately!\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    df: dataframe containing the missing values\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    df_ret: dataframe with fixed values\n",
    "    \"\"\"\n",
    "    df_ret = df.copy()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    from pandas.tseries.offsets import DateOffset\n",
    "    df_ret = df_ret.reset_index().sort_values(by = ['year','month','week', 'day','hour'])\n",
    "\n",
    "    for index, row in df_ret[df_ret['temp'].isna()].iterrows():\n",
    "        date = row['date']\n",
    "        hour = row['hour']\n",
    "\n",
    "        day_before = date - pd.DateOffset(days = 1)\n",
    "        day_after = date + pd.DateOffset(days = 1)\n",
    "\n",
    "        temp_before = df_ret[(df_ret['date'] == day_before) & (df_ret['hour'] == hour)]['temp'].values[0]\n",
    "        temp_after = df_ret[(df_ret['date'] == day_after) & (df_ret['hour'] == hour)]['temp'].values[0]\n",
    "\n",
    "        new_temp = np.average([temp_before, temp_after])\n",
    "\n",
    "        df_ret.loc[(df_ret['date'] == date) & (df_ret['hour'] == hour), 'temp'] = new_temp\n",
    "\n",
    "    df_ret['temp'] = df_ret['temp'].fillna(df_ret['temp'].mean())\n",
    "    \n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WnAENjaWrMJS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72d6c9e5c223d3ca987fae352250b04a",
     "grade": false,
     "grade_id": "cell-ce0654819c0f89a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Plot the fixed stretch of temp values from above, and compare to the unmodified version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPXJ-60Es1rJ",
    "revert": "missing_temp_idx = 0"
   },
   "outputs": [],
   "source": [
    "missing_temp_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "deletable": false,
    "editable": false,
    "id": "DvaxF9HprGDn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab019b7ae8b408f14a0228b2832beb6c",
     "grade": false,
     "grade_id": "cell-b1ee5ba109485ab6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "ca9ae8e9-dbe9-4227-c205-f682a255646d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!! \n",
    "plot_value_series(missing_temp_df_list[missing_temp_idx], 'temp')\n",
    "plot_value_series(handle_missing_temp_values(missing_temp_df_list[missing_temp_idx]), 'temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vtngIM0LtH2K",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fbe30b2adbd9d72d0b621374c6dd2f8",
     "grade": false,
     "grade_id": "cell-5ead27560ac73c21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Handle missing air pressure values\n",
    "\n",
    "Do the same for the air pressure values:\n",
    "\n",
    "- Implement the function below to get rid of the missing values for air pressure (`airPressure`).\n",
    "- Choose an appropriate strategy to fill in the misssing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "EccqDJHM5PDu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2d9f4fa8e3bc564bf6699e95bb51973",
     "grade": false,
     "grade_id": "cell-00257539969e677d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def handle_missing_airPressure_values(df:pd.DataFrame) -> pd.DataFrame:\n    \"\"\" \n    Handle missing air pressure values appropriately!\n\n    Parameters\n    --------\n    df: dataframe containing the missing values\n    \n    Returns\n    --------\n    df_ret: dataframe with fixed values\n    \"\"\"\n    df_ret = df.copy()\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return df_ret",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_missing_airPressure_values(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Handle missing air pressure values appropriately!\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    df: dataframe containing the missing values\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    df_ret: dataframe with fixed values\n",
    "    \"\"\"\n",
    "    df_ret = df.copy()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    from pandas.tseries.offsets import DateOffset\n",
    "    df_ret = df_ret.reset_index().sort_values(by = ['year','month','week', 'day','hour'])\n",
    "\n",
    "    # for index, row in df_ret[df_ret['airPressure'].isna()].iterrows():\n",
    "    #     date = row['date']\n",
    "    #     hour = row['hour']\n",
    "\n",
    "    #     day_before = date - pd.DateOffset(days = 1)\n",
    "    #     day_after = date + pd.DateOffset(days = 1)\n",
    "\n",
    "    #     temp_before = df_ret[(df_ret['date'] == day_before) & (df_ret['hour'] == hour)]['airPressure'].values[0]\n",
    "    #     temp_after = df_ret[(df_ret['date'] == day_after) & (df_ret['hour'] == hour)]['airPressure'].values[0]\n",
    "\n",
    "    #     new_temp = np.average([temp_before, temp_after])\n",
    "\n",
    "    #     df_ret.loc[index, 'airPressure'] = new_temp\n",
    "\n",
    "    df_ret['airPressure'] = df_ret['airPressure'].fillna(df_ret['airPressure'].mean())\n",
    "        \n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "NCQV5u0arP4y",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2384a86d477e7ed0b960f6cc3901d1d",
     "grade": false,
     "grade_id": "cell-42170186b903fa8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Plot the fixed stretch of airPressure values from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3nA5TMdktTNL",
    "revert": "missing_apr_idx = 0"
   },
   "outputs": [],
   "source": [
    "missing_apr_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "deletable": false,
    "editable": false,
    "id": "qiYtkFj2rKkN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25fc17223183a7dbe1df7d47a707ce02",
     "grade": false,
     "grade_id": "cell-758ade40091745fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "487f8248-5f18-45ac-8ff2-aefed24d1a3e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!! \n",
    "plot_value_series(missing_airPressure_df_list[missing_apr_idx], 'airPressure')\n",
    "plot_value_series(handle_missing_airPressure_values(missing_airPressure_df_list[missing_apr_idx]), 'airPressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "R_D1L9P66Cn1",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e08e5a42483f0880afce152d85e0c7a8",
     "grade": true,
     "grade_id": "cell-2cf3f24221001ad2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tests, DO NOT MODIFY OR COPY THIS CELL!!\n",
    "# the function to get the short dataframes around missing values should now return an empty list if we fix all temp values!\n",
    "empty_temp_list = get_data_around_missing(handle_missing_temp_values(weather_data), 'temp')\n",
    "empty_airPressure_list = get_data_around_missing(handle_missing_airPressure_values(weather_data), 'airPressure')\n",
    "assert len(empty_temp_list) == 0\n",
    "assert len(empty_airPressure_list) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "aaTlWw60gtyY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6de6cb4357d4cb1d68cc6b65f6d3000",
     "grade": true,
     "grade_id": "cell-f8f38e4afd62d60c",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "2afa1df6-d5da-40da-b46c-93fb25cbe536",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ny5dyD7r6Xma",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d9e2f3cb225529b67060466a0da8d94",
     "grade": false,
     "grade_id": "cell-a51cbd28ea3be623",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 2.2 Missing wind direction values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hxGRYrYwuZgO",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "455a706e0bfbc0284ee44d90618b9330",
     "grade": false,
     "grade_id": "cell-06f5896452f12539",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Data inspection\n",
    "Check the assumption for missing wind direction values and handle the missing wind direction values in an appropriate way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "zesuPfOH6zIg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41848449b56855b496952bede20f9fb7",
     "grade": false,
     "grade_id": "cell-c933b4f1e3715277",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "a97a280d-1dba-4eb6-ea93-f22c96f42ec1",
    "revert": "# write some code to check the assumtion for missing values of windDir\n\n# YOUR CODE HERE\nraise NotImplementedError()",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write some code to check the assumtion for missing values of windDir\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "weather_data[weather_data['windDir'].isna()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bULyq8IXmQEr",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ecd0121f5259bc12599c07e86ff8b997",
     "grade": false,
     "grade_id": "cell-6d3922c4bfb994a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Handle missing wind direction values\n",
    "Implement a function that fixes the missing wind direction values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "mO5ejRGV6lW6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69a217174a1159f2b8268d591e66398a",
     "grade": false,
     "grade_id": "cell-c33d51f182502006",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def handle_missing_windDir_values(df:pd.DataFrame) -> pd.DataFrame:\n    df_ret = df.copy()\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return df_ret",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_missing_windDir_values(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    df_ret = df.copy()\n",
    "\n",
    "    df_ret['windDir'] = df_ret['windDir'].ffill()\n",
    "\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cJAVM8eN7VED",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5efe20adc6a56869405752b537b518da",
     "grade": true,
     "grade_id": "cell-ce2bff11f39581ce",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tests, DO NOT MODIFY OR COPY THIS CELL!!\n",
    "# Apply the windDir fix and check if any missing values remain\n",
    "fix_wind_dir = handle_missing_windDir_values(weather_data)\n",
    "assert fix_wind_dir[fix_wind_dir['windDir'].isnull()].empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "Gnm2XGzU75YI",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f20037dd90f3c1f920cd7b413835cd3",
     "grade": true,
     "grade_id": "cell-a7acfa49bbade2bb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "99ab78a1-2f7b-489b-b5b5-9886e5f24577",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZNR9aDpnv5Hh",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ad883ec35d98e7ab76f4ac990ef6f88",
     "grade": false,
     "grade_id": "cell-abb04829152394aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 2.3 Combine all fixes to get clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "sDQ7RvMpuJgc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fd4c2c8a9a1d676835d7985928af647",
     "grade": false,
     "grade_id": "cell-5d75102f5d1c5d81",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def handle_missing_values_weather(data:pd.DataFrame) -> pd.DataFrame:\n    \"\"\" \n    Parameters\n    --------\n    data: data frame containing missing values \n    \n    Returns\n    --------\n    data: data frame not containing any missing values\n    \"\"\"\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n    \n    return data",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_missing_values_weather(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    --------\n",
    "    data: data frame containing missing values \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    data: data frame not containing any missing values\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    data = handle_missing_temp_values(data)\n",
    "    data = handle_missing_airPressure_values(data)\n",
    "    data = handle_missing_windDir_values(data)\n",
    "\n",
    "    data = data.set_index(keys = ['year','month','week','day','hour']).drop(columns = 'index')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xMTGc5yp_d5C",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e4e9f28d4e2721052ac8e7f1a3dfb88",
     "grade": false,
     "grade_id": "cell-62d215809c95ce8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!!\n",
    "weather_data_complete = handle_missing_values_weather(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-xlZiZSuJgc",
    "outputId": "17105504-d0e8-4d1c-ecb3-8c6d1ee1e12f",
    "revert": "print(f\"Before: \\n---------\\n{weather_data.isna().sum()}\")\nprint(f\"\\nAfter: \\n---------\\n{weather_data_complete.isna().sum()}\")",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Before: \\n---------\\n{weather_data.isna().sum()}\")\n",
    "print(f\"\\nAfter: \\n---------\\n{weather_data_complete.isna().sum()}\")\n",
    "\n",
    "print(weather_data_complete.shape)\n",
    "print(weather_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Z_kh77J_uJgc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "957027f6ac203b3eb1a9c49236ebece7",
     "grade": true,
     "grade_id": "cell-5c715e67d037b3a2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tests, DO NOT MODIFY OR COPY THIS CELL!!\n",
    "# check if missing values are no longer present\n",
    "assert not weather_data_complete.isna().any().any()\n",
    "assert weather_data_complete.shape[0] == weather_data.shape[0]\n",
    "assert weather_data_complete.shape[1] == weather_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wAxHGzluuJge",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "775875e9307b85a0648124051a2d7649",
     "grade": false,
     "grade_id": "cell-95ba70db2931e676",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 3: Handling Outliers (10 Points)\n",
    "\n",
    "Additionally to the missing values, the dataset also seems to have some strange values, that are probably outliers. \n",
    "When confronted with the data, the meterologist gave you a bit more information:\n",
    "\n",
    "\n",
    "1. Sometimes the temperture readings seem to be off, without any good reason.\n",
    "\n",
    "2. In the timespan from early October 2015 until mid March 2016, the wind sensor was defective: it might have displayed wrong values for winds from SE direction.\n",
    "\n",
    "3. In the `daily_weather_data`, the precipitation column contains some non-numeric values.\n",
    "\n",
    "4. The precipitation sensor usually produces wrong values when hail is involved.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "BexkhzjsQvR8",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7850b6b2c088b0ca6657ffad1e9abfaf",
     "grade": false,
     "grade_id": "cell-9d76f6b444ed107c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3.1 Temperature outliers\n",
    "First we want ot take a closer look at the temperature values. Check if we can identify some obvious outliers and come up with a strategy to handle/fix them.\n",
    "\n",
    "In order to do so you will have to:\n",
    "- Plot the temperature curve over time and a histogram of temperature values to identify possible outliers\n",
    "- Plot a zoomed in version of individual outliers to get a better understanding what's happening\n",
    "- Devise a strategy to get rid of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MYpW_ceXCrD_",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "835e415b3c65e1ec328f6bcd39db0919",
     "grade": false,
     "grade_id": "cell-e27f7970f94300a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Investigation\n",
    "Implement the function below to create a plot of the temperature values (`temp`) over time. Additionally create a histogram with reasonable bins to identify the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "dCIF6qFeuJge",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16b9965a0dd8059f6003f7cfcd87762a",
     "grade": false,
     "grade_id": "cell-1c4dc7b33eff42b2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def plot_temp_analysis(df: pd.DataFrame) -> None:\n    \"\"\"\n    Create two plots:\n    1) Temperature values over time for the whole dataframe\n    2) A histogram for temperature values. \n       Choose appropriate bins enabling you to identify outliers!\n\n    Parameters\n    --------\n    df: data frame containint the temperature values (temp) with potential outlier\n    \n    \"\"\"\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_temp_analysis(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Create two plots:\n",
    "    1) Temperature values over time for the whole dataframe\n",
    "    2) A histogram for temperature values. \n",
    "       Choose appropriate bins enabling you to identify outliers!\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    df: data frame containint the temperature values (temp) with potential outlier\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    df = df.sort_values(by = 'date')\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(df['date'], df['temp'])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.hist(df['temp'], range = (60,90))\n",
    "\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "deletable": false,
    "editable": false,
    "id": "Gq4TPDi_WRIT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3bab2e51e11f7add00f55a7d869db31",
     "grade": false,
     "grade_id": "cell-1aec9f728860adc3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "1ccb303b-4d94-475c-a0b7-5d1ededac111",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!!\n",
    "plot_temp_analysis(weather_data_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "deletable": false,
    "editable": false,
    "id": "2AnCVNlHuJge",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f86b682ee2c74ee86d893db5c531c6f",
     "grade": true,
     "grade_id": "cell-df82f689aa8b7a00",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "4900bbcf-b6f9-4ef0-ed52-05999d4c3de8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden test, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TePz2DQsSG4a",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5036dd4d33e5174aea54f286acce177e",
     "grade": false,
     "grade_id": "cell-7a329a092512ed2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "In the next cell, select a random outlier (e.g. the first) and plot the temperature curve around the outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "deletable": false,
    "id": "tDrvoaZAuJgf",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2092de03083f8cbecedd8b7d5fca314c",
     "grade": false,
     "grade_id": "cell-17539c832c250be2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "e3911478-f166-4f11-9157-1a79498b7ca1",
    "revert": "# YOUR CODE HERE\nraise NotImplementedError()",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "outlier = weather_data_complete[weather_data_complete['temp'] > 60]['date'].to_list()[5]\n",
    "\n",
    "ts = pd.Timestamp(outlier)\n",
    "\n",
    "start_date = ts - DateOffset(days = 10)\n",
    "end_date = ts + DateOffset(days = 10)\n",
    "\n",
    "\n",
    "outliers = weather_data_complete[(weather_data_complete['date'] >= start_date) & (weather_data_complete['date'] <= end_date)][['date','temp']].sort_values(by = 'date')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(outliers['date'], outliers['temp'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "deletable": false,
    "editable": false,
    "id": "7Yl86jZ9UltA",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82c15a435eebfe1d6b9e19666e7ea912",
     "grade": true,
     "grade_id": "cell-8e4efdee79059360",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "96c1dcbb-bbf2-4ad6-ba35-be1b1a2297a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden test, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_ToKPeEMV9nm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41f31defd29cf5a99eb52d9f9552ee02",
     "grade": false,
     "grade_id": "cell-52c19138292f3072",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Remove temperature outliers\n",
    "Implement the below function using the strategy you defined above to get rid of the temperature outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "g-cLMXnPuJgh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a6fbee789818ca2d63453b46fba9799",
     "grade": false,
     "grade_id": "cell-3a5e129500b7c7fa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def handle_temp_outliers(noisy_data) -> pd.DataFrame:\n    \"\"\"\n    Parameters\n    --------\n    noisy_data: data frame that contains temperature outliers ('temp' column)\n\n    Returns\n    --------\n    cleaned_data: data frame with temperature outliers removed/handled\n    \"\"\"\n    cleaned_data = noisy_data.copy()\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return cleaned_data",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_temp_outliers(noisy_data) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------\n",
    "    noisy_data: data frame that contains temperature outliers ('temp' column)\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    cleaned_data: data frame with temperature outliers removed/handled\n",
    "    \"\"\"\n",
    "    cleaned_data = noisy_data.copy()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    Q3 = noisy_data['temp'].quantile(0.75)\n",
    "    Q1 = noisy_data['temp'].quantile(0.25)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    upper = Q3 + 1.5*IQR\n",
    "    lower = Q1 - 1.5*IQR\n",
    "\n",
    "    cleaned_data['temp'] = cleaned_data['temp'].clip(lower = lower, upper = upper)\n",
    "\n",
    "\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "deletable": false,
    "editable": false,
    "id": "3EneqlYXV0B9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5acf4671f4daaf123698b7db0f99fa53",
     "grade": false,
     "grade_id": "cell-af34b47f99a17c3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "ec5c025f-c126-422b-d92d-b1451eedd7ac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!!\n",
    "weather_data_cleaned = handle_temp_outliers(weather_data_complete)\n",
    "plot_temp_analysis(weather_data_cleaned)\n",
    "print(weather_data_cleaned['temp'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YA_EQ6ZiuJgi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af315ec1a9ded75934eb6055da3f7ed0",
     "grade": true,
     "grade_id": "cell-1eae97f921d127d4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test, DO NOT MODIFY OR COPY THIS CELL!!\n",
    "\n",
    "# check if new missing values were introduced\n",
    "assert not weather_data_cleaned.isna().any().any()\n",
    "# check if outliers were simply dropped\n",
    "assert weather_data_cleaned.shape == weather_data_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bQ1GjpRUuJgi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9c6fa3f4a31724c7cc9950bff6fb37d",
     "grade": true,
     "grade_id": "cell-95c195c3b2b9dc83",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden test, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "x-APz1IcuJgi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ee5d829f5847930303a901c3e75f5cc",
     "grade": true,
     "grade_id": "cell-66671e0f9a6b08e6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "4f0ca89e-2e6a-4f7f-f233-6b66b9813c0f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden test, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9bwgpZ1J8k3U",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d96f825b65dfedb4188dda63f0fd1b8a",
     "grade": false,
     "grade_id": "cell-a8502a2937a35649",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3.2 Wind speed outliers\n",
    "\n",
    "The second outlier problem was, that in the timespan from early October 2015 until mid March 2016, the wind sensor was defective: it might have displayed wrong values for winds from SE direction.\n",
    "\n",
    "Double check if this is true, and if it is, fix the values appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zhlyPb69ukSD",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b52d46bd7e2cb62f0f46ef0e087caf91",
     "grade": false,
     "grade_id": "cell-e5437753497e1f41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Data inspection\n",
    "\n",
    "Implement the function below to visualize the problematic wind sensor data.\n",
    "Complete the function below to check the assumtions for wrong values of windBeauf.\n",
    "- Plot the wind speed data over the questionable time duration (early October 2015 until mid March 2016)\n",
    "- Plot a histogram of the windspeed values to identify outliers\n",
    "- Check if the assumtion regarding the wind direction is true (errors only from SE direction)\n",
    "\n",
    "Bonus:\n",
    "- Find out when exactly the sensor started to produce wrong values and when the sensor was fixed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "MWIzCHIW8ur7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b1c6253844f901f31a3d026b3fab6d3",
     "grade": false,
     "grade_id": "cell-17a134d20f0b933f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def analyze_wind_range(df:pd.DataFrame) -> typing.Tuple[int, typing.List[str]]:\n    \"\"\"\n    Plot analysis plots for the wind data. Print outputs about relevant data \n    and return the relevant values as indicated.\n\n    Parameters\n    --------\n    noisy_data: data frame that contains outliers\n    \n    Returns\n    --------\n    wind_dir_outliers: list of wind direction string code, for which outliers where found\n    num_outliers: number of found outliers\n\n    \"\"\"\n\n    num_outliers = 0  # return a value that reflects how many outliers you identified\n    wind_dir_outliers = [] # a list of the string codes for wind directions where you identified outliers from\n\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return wind_dir_outliers, num_outliers\n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_wind_range(df:pd.DataFrame) -> typing.Tuple[int, typing.List[str]]:\n",
    "    \"\"\"\n",
    "    Plot analysis plots for the wind data. Print outputs about relevant data \n",
    "    and return the relevant values as indicated.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    noisy_data: data frame that contains outliers\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    wind_dir_outliers: list of wind direction string code, for which outliers where found\n",
    "    num_outliers: number of found outliers\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    num_outliers = 0  # return a value that reflects how many outliers you identified\n",
    "    wind_dir_outliers = [] # a list of the string codes for wind directions where you identified outliers from\n",
    "\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    start_date = pd.Timestamp(year = 2015, month = 10, day = 1)\n",
    "    end_date = pd.Timestamp(year = 2016, month = 3, day = 15)\n",
    "\n",
    "    time_in_question = df[(df['date'] >= start_date) & (df['date'] <= end_date)].sort_values(by = 'date')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(time_in_question['date'], time_in_question['windBeauf'])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # Find Outliers with IQR\n",
    "\n",
    "    Q3 = time_in_question['windBeauf'].quantile(0.75)\n",
    "    Q1 = time_in_question['windBeauf'].quantile(0.25)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    upper = Q3 + 1.5*IQR\n",
    "    lower = Q1 - 1.5*IQR\n",
    "\n",
    "    outliers = time_in_question[(time_in_question['windBeauf'] <= lower) | (time_in_question['windBeauf'] >= upper)]\n",
    "\n",
    "    num_outliers = (outliers.count()[0])\n",
    "\n",
    "    wind_dir_outliers = outliers['windDir'].to_list()\n",
    "\n",
    "    return wind_dir_outliers, num_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "deletable": false,
    "editable": false,
    "id": "ErQSjD54YJkP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "267978981c19747bdb9d4c97f7df7c89",
     "grade": false,
     "grade_id": "cell-372397c0c89b806b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "cdb8e0cb-5174-467d-ae3b-4534d4c26357",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!!\n",
    "wind_dir_outliers, num_outliers = analyze_wind_range(weather_data_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "deletable": false,
    "editable": false,
    "id": "d70D2VsBdeQV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81b57d97671100a5fe2183da91a62865",
     "grade": true,
     "grade_id": "cell-8c1a7fd690b311ea",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "4f61a7b2-b6de-44ea-93a0-c4d3a856bf04",
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert 0 < num_outliers < 500, \"there should be more than zero but less than 500 outliers!\"\n",
    "assert len(wind_dir_outliers) > 0, \"there should be at least one wind direction!\"\n",
    "assert isinstance(wind_dir_outliers[0], str), \"the wind direction codes are strings with two characters!\"\n",
    "assert len(wind_dir_outliers[0]) == 2, \"the wind direction codes are strings with two characters!\"\n",
    "\n",
    "# hidden test, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xHdePkuZmXfH",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75bcb0dd7c541b9fceb64e81c5e84a30",
     "grade": false,
     "grade_id": "cell-9071c87920503ad5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Fix wind sensor outliers\n",
    "Fix the values appropriately. Implement a function that compensates for the problem you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "jOAgaeWBmnS7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "860e0eccb270ed90abd4c07c931e7d40",
     "grade": false,
     "grade_id": "cell-43854ccdb6d35121",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def fix_windBeauf_values(df:pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Parameters\n    --------\n    df: data frame that contains potential faulty wind values\n\n    Returns\n    -------\n    df_ret: data frame with fixed wind values\n    \"\"\"\n\n    df_ret = df.copy()\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return df_ret",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_windBeauf_values(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------\n",
    "    df: data frame that contains potential faulty wind values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_ret: data frame with fixed wind values\n",
    "    \"\"\"\n",
    "\n",
    "    df_ret = df.copy()\n",
    "\n",
    "    Q3 = df_ret['windBeauf'].quantile(0.75)\n",
    "    Q1 = df_ret['windBeauf'].quantile(0.25)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    upper = Q3 + 1.5*IQR\n",
    "    lower = Q1 - 1.5*IQR\n",
    "\n",
    "    df_ret['windBeauf'] = df_ret['windBeauf'].clip(lower = lower, upper = upper)\n",
    "\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "deletable": false,
    "editable": false,
    "id": "k-IgDi3FKs9q",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91f769d94aa10f92bbe5358156cdf0e0",
     "grade": false,
     "grade_id": "cell-f760730c20adf117",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "4371c711-ca7f-41bc-e3b0-1a0776e19bc2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test, DO NOT MODIFY OR COPY THIS CELL!!\n",
    "weather_data_fix_wind = fix_windBeauf_values(weather_data_complete)\n",
    "wind_dir_outliers_fixed, num_outliers_fixed = analyze_wind_range(weather_data_fix_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "taRBcC0LfAmJ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d07275af456e38042b5ca5debe01fd9b",
     "grade": true,
     "grade_id": "cell-786e83740a6bc58d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "265a5326-f200-471c-f21f-c96fc2cabeb8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test, DO NOT MODIFY OR COPY THIS CELL!!\n",
    "assert num_outliers_fixed == 0, \"now no outliers should be found\"\n",
    "assert len(wind_dir_outliers_fixed) == 0, \"now no outliers should be found, so no directions!\"\n",
    "assert weather_data_fix_wind.shape == weather_data_complete.shape\n",
    "\n",
    "# hidden test, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "uSbJNujUy0I6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59e36a11c8dd6018a9cc7c9eff3806f5",
     "grade": false,
     "grade_id": "cell-dbe56ebadc8e24b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3.3 Daily weather data: precipitation\n",
    "\n",
    "When loading the data, we separated the precipitation data into the `daily_weather_data` dataframe.\n",
    "This dataframe also has an issues:\n",
    "\n",
    "- The `precip` column contains some non-numeric values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3R54abDF77BU",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63bfa0ed8f8f9fdc5907fd9dcfb564b1",
     "grade": false,
     "grade_id": "cell-7c63005a3c8d57d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Data inspection\n",
    "Check the occurance of the non-numeric values in the precipitation data. You can check the file `data/weather/description.txt`, which might have additional clues what is going on.\n",
    "\n",
    "Implement the function below and return a list of the non-numeric values that occur in the `precip` column of `daily_weather_data`. Make sure to only return every unique value once! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "o5cfdD-W15LI",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5610eb260d0674286cc80c2da030016",
     "grade": false,
     "grade_id": "cell-6cc9d49c1e439440",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def get_non_numeric_precip_values(df:pd.DataFrame) -> typing.Set[str]:\n    \"\"\"\n    Parameters\n    --------\n    df: data frame that contains non-numeric values in precip column\n\n    Returns\n    -------\n    non_numeric_values: list of unique non-numeric values. \n    Do not return duplicate values in the list!\n    \"\"\"\n    non_numeric_values = set()\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return non_numeric_values",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_non_numeric_precip_values(df:pd.DataFrame) -> typing.Set[str]:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------\n",
    "    df: data frame that contains non-numeric values in precip column\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    non_numeric_values: list of unique non-numeric values. \n",
    "    Do not return duplicate values in the list!\n",
    "    \"\"\"\n",
    "    non_numeric_values = set()\n",
    "\n",
    "    vals = set(df['precip'].unique())\n",
    "\n",
    "    for val in vals:\n",
    "        try:\n",
    "            float(val)\n",
    "        except:\n",
    "            non_numeric_values.add(val)\n",
    "    \n",
    "\n",
    "    return non_numeric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "3UgLjARvFfWx",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38d2e8cbc350bf1c70314658a1209887",
     "grade": false,
     "grade_id": "cell-39be2818c445057c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c954b15f-261f-467a-ae57-4de4c32bb3db",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!!\n",
    "non_numeric_values = get_non_numeric_precip_values(daily_weather_data)\n",
    "print(f\"\\nnon-numeric values values: {non_numeric_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ok0a-9Z1Khju",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e1dbaa6bff512bd384d89f3a5addd10",
     "grade": true,
     "grade_id": "cell-ebad3db2e9939f5b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tests, DO NOT MODIFY OR COPY THIS CELL!!\n",
    "assert isinstance(non_numeric_values, set) , \"make sure to return a set, so no duplicate values can be returned!!\"\n",
    "assert len(non_numeric_values) > 0, \"there should be some non-numeric values in daily_weather_data!\"\n",
    "assert isinstance(list(non_numeric_values)[0], str), \"only return the non-numeric values as strings!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "nsx9Uv2f8CEc",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da1b5297122adef8fefac71e3f023efe",
     "grade": false,
     "grade_id": "cell-8f4422157a413f9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Fix non-numeric values\n",
    "Replace non-numeric values with some appropriate numerical values and convert the column to a more suitable data type.\n",
    "To get an idea, what appropriate values might be, check the file `data/weather/description.txt` and the other numeric values in the `precip` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "SCMOFxqxy9s1",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "205fd4f77f9911b48c19e61c66e34655",
     "grade": false,
     "grade_id": "cell-b4ca9c25b4e2a451",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def fix_precip_values(df:pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Parameters\n    --------\n    df: data frame that contains non-numeric values in precip column\n\n    Returns\n    -------\n    ret_df: data frame with fixed precip values\n    \"\"\"\n    ret_df = df.copy()\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return ret_df",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_precip_values(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------\n",
    "    df: data frame that contains non-numeric values in precip column\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ret_df: data frame with fixed precip values\n",
    "    \"\"\"\n",
    "    ret_df = df.copy()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    ret_df['precip'] = ret_df['precip'].replace('traces', 0.01)\n",
    "\n",
    "    ret_df['precip'] = ret_df['precip'].apply(pd.to_numeric)\n",
    "\n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xHUR3t_01Oyo",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1901afde303a75bca4f8131f70f0ae3",
     "grade": false,
     "grade_id": "cell-22184a57d9e5018c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!!\n",
    "daily_weather_data_fixed_precip = fix_precip_values(daily_weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_tRzz1Quu_Hi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54387ed5d7c22908ce761a5cdf97eac9",
     "grade": true,
     "grade_id": "cell-cc5b5f0d50fd0553",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test, DO NOT MODIFY OR COPY THIS CELL!!\n",
    "assert pd.api.types.is_float_dtype(daily_weather_data_fixed_precip['precip'].dtype), \"precip should now be a float column!!\"\n",
    "assert daily_weather_data_fixed_precip.shape == daily_weather_data.shape, \"do not remove or add rows!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "k8eo4dzXlHvf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6e104821c8d9b84f8d2835b8c038446",
     "grade": false,
     "grade_id": "cell-cf9b0dcce316b0f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Combining the fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "REzLe-qsNde2",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ef019b409be22c7e3013154daf12914",
     "grade": false,
     "grade_id": "cell-9d0369dd3eeef578",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!!\n",
    "def fix_values_daily(data):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    --------\n",
    "    data: data frame containing missing values \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    complete_data: data frame not containing any missing values\n",
    "    \"\"\"\n",
    "    complete_data = data.copy()\n",
    "    complete_data = fix_precip_values(complete_data)\n",
    "    \n",
    "    return complete_data\n",
    "\n",
    "   \n",
    "def handle_outliers(data):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    --------\n",
    "    data: data frame containing outlier values \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    complete_data: data frame not containing any outlier values\n",
    "    \"\"\"\n",
    "    complete_data = data.copy()\n",
    "    complete_data = handle_temp_outliers(complete_data)\n",
    "    complete_data = fix_windBeauf_values(complete_data)\n",
    "    \n",
    "    return complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FSoRiVTClQEx",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ec2b301c10ebe8fb98331f5fa8ae726",
     "grade": false,
     "grade_id": "cell-7eaa301cd8991d72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!!\n",
    "daily_weather_data_finished = fix_values_daily(daily_weather_data)\n",
    "weather_data_finished = handle_outliers(weather_data_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ozyHsyZRuJgi",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a91d2af92e8cf45709f8fa78106c7480",
     "grade": false,
     "grade_id": "cell-91bc351485145c37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 4: Aggregate values (5 Points)\n",
    "\n",
    "Aggregate the observations on a weekly basis. Return a data frame with a hierarchical index (levels `year` and `week`) and the following weekly aggregations as columns:\n",
    "\n",
    "- `temp_weeklyMin`: minimum of `temp`\n",
    "- `temp_weeklyMax`: max of `temp`\n",
    "- `temp_weeklyMean`: mean of `temp`\n",
    "- `temp_weeklyMedian`: median of `temp`\n",
    "\n",
    "- `hum_weeklyMin`: min of `hum`\n",
    "- `hum_weeklyMax`: max of `hum`\n",
    "- `hum_weeklyMean`: mean of `hum`\n",
    "\n",
    "- `wind_weeklyMean`: mean of `windBeauf`\n",
    "- `wind_weeklyMax`: max of `windBeauf`\n",
    "- `wind_weeklyMin`: min of `windBeauf`\n",
    "\n",
    "Additionally merge the precipitation values from the `daily_weather_data` dataframe also into the newly created dataframe and aggregate them into the folling columns:\n",
    "- `precip_weeklyMin`: min of `precip`\n",
    "- `precip_weeklyMax`: max of `precip`\n",
    "- `precip_weeklyMean`: mean of `precip`\n",
    "\n",
    "\n",
    "**Note:** Attentive data scientists might have noticed a problem with isocalendars when aggregating on `Year` and `Week`. You can ignore this for the purpose of this lecture. In real-world settings you might consider addressing this issue, depending on your task and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "gw4FwbkZFrfq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe9fe86a409a6b547189e3bed9cb9046",
     "grade": false,
     "grade_id": "cell-814c7b7dc89c8f64",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def aggregate_weekly(hourly_data, data_daily):\n    \"\"\" \n    Parameters\n    --------\n    hourly_data: hourly weather data frame, containing temp, hum, and wind values.\n    data_daily: daily weather data frame with precip values\n    \n    Returns\n    --------\n    weekly_stats: data frame that contains statistics aggregated on a weekly basis\n    \"\"\"\n    weekly_weather_data = pd.DataFrame()\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return weekly_weather_data",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggregate_weekly(hourly_data, data_daily):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    --------\n",
    "    hourly_data: hourly weather data frame, containing temp, hum, and wind values.\n",
    "    data_daily: daily weather data frame with precip values\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    weekly_stats: data frame that contains statistics aggregated on a weekly basis\n",
    "    \"\"\"\n",
    "    weekly_weather_data = pd.DataFrame()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    weekly_weather_data['temp_weeklyMin'] = hourly_data.groupby(by = ['year','week'])['temp'].min()\n",
    "    weekly_weather_data['temp_weeklyMax'] = hourly_data.groupby(by = ['year','week'])['temp'].max()\n",
    "    weekly_weather_data['temp_weeklyMean'] = hourly_data.groupby(by = ['year','week'])['temp'].mean()\n",
    "    weekly_weather_data['temp_weeklyMedian'] = hourly_data.groupby(by = ['year','week'])['temp'].median()\n",
    "    \n",
    "    weekly_weather_data['hum_weeklyMin'] = hourly_data.groupby(by = ['year','week'])['hum'].min()\n",
    "    weekly_weather_data['hum_weeklyMax'] = hourly_data.groupby(by = ['year','week'])['hum'].max()\n",
    "    weekly_weather_data['hum_weeklyMean'] = hourly_data.groupby(by = ['year','week'])['hum'].mean()\n",
    "\n",
    "    weekly_weather_data['wind_weeklyMin'] = hourly_data.groupby(by = ['year','week'])['windBeauf'].min()\n",
    "    weekly_weather_data['wind_weeklyMax'] = hourly_data.groupby(by = ['year','week'])['windBeauf'].max()\n",
    "    weekly_weather_data['wind_weeklyMean'] = hourly_data.groupby(by = ['year','week'])['windBeauf'].mean()\n",
    "\n",
    "    weekly_weather_data['precip_weeklyMin'] = data_daily.groupby(by = ['year','week'])['precip'].min()\n",
    "    weekly_weather_data['precip_weeklyMax'] = data_daily.groupby(by = ['year','week'])['precip'].max()\n",
    "    weekly_weather_data['precip_weeklyMean'] = data_daily.groupby(by = ['year','week'])['precip'].mean()\n",
    "\n",
    "    return weekly_weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "deletable": false,
    "editable": false,
    "id": "17cXRq3YGCwW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6b2f79f631e46781f73f0d9bda1fbdf",
     "grade": false,
     "grade_id": "cell-1be305df9f6b19d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "fabc0069-4251-43e3-a61a-82dc9b02148b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!!\n",
    "weekly_weather_data = aggregate_weekly(weather_data_finished, daily_weather_data_finished)\n",
    "display(weekly_weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mv9a5NFpSS4e",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adb1235c62018d806de34fc2229e0def",
     "grade": true,
     "grade_id": "cell-64e14d2afe613066",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tests, DO NOT MODIFY OR COPY THIS CELL!!\n",
    "assert len(weekly_weather_data.columns) >= 13, \"according to the instructions, the dataframe should have >= 13 columns\"\n",
    "assert len(weekly_weather_data.index.levels) == 2, \"according to the instructions, the dataframe should have a multi-index with 2 levels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "beFq8xgzGgFn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b1eefc1cc82699da087a51b16d576cc",
     "grade": true,
     "grade_id": "cell-e217ee3c67fb1741",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "6f1430b9-d738-4105-c504-017b68e7568e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hidden tests, DO NOT MODIFY OR COPY THIS CELL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MeiElpzcuJgk",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a6c626ebd7f4a0e036b7b30a62afe2d",
     "grade": false,
     "grade_id": "cell-9af4a99364cf35b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Task 5: Merge influenza and weather datasets (5 Points)\n",
    "\n",
    "Merge the `data_weather_weekly` and `data_influenza` datasets.\n",
    "Both dataframes should now be on a weekly index. \n",
    "Beware that both datasets contain rows that do not appear in the other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "PygtKVk8uJgk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd5ce0da72b1eadc1d953bc810bf38d1",
     "grade": true,
     "grade_id": "cell-111898bc4759240a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c8d9eb35-1bc3-4d52-ca28-e4b84e1d121f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tests, DO NOT MODIFY OR COPY THIS CELL!!\n",
    "# Neither of the tables contain missing data\n",
    "\n",
    "print(f\"influenza data, missing data (should be 0): \\n{data_influenza.isna().sum()}\")\n",
    "print(f\"weather data, missing data (should be 0): \\n{weekly_weather_data.isna().sum()}\")\n",
    "\n",
    "assert not data_influenza.isna().any().any(), \"we should have eliminated all missing values!!\"\n",
    "assert not weekly_weather_data.isna().any().any(), \"we should have eliminated all missing values!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "deletable": false,
    "id": "4YIV8xKZuJgk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "233b90b0c565bdbc5a0e04508563fe0b",
     "grade": false,
     "grade_id": "cell-c2a5c9759cebd589",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "fee1e259-7ba1-4e0f-f61b-58ad4dc25312",
    "revert": "# use this cell for experimentation / analysis for merging data\n\n# YOUR CODE HERE\nraise NotImplementedError()",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use this cell for experimentation / analysis for merging data\n",
    "\n",
    "# YOUR CODE HERE\n",
    "weekly_weather_data\n",
    "# data_influenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "YSRXSMZfuJgl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ffed0652729f1cc06611ffd331e2c0f",
     "grade": false,
     "grade_id": "cell-b6d550e9d33d1784",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def merge_data(weather_df, influenza_df):\n    \"\"\" \n    Parameters\n    --------\n    weather_df: weekly weather data frame\n    influenza_df: influenza data frame\n    \n    Returns\n    --------\n    merged_data: merged data frame that contains both weekly weather observations and prevalence of influence infections\n    \"\"\"\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return merged_data",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_data(weather_df, influenza_df):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    --------\n",
    "    weather_df: weekly weather data frame\n",
    "    influenza_df: influenza data frame\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    merged_data: merged data frame that contains both weekly weather observations and prevalence of influence infections\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    merged_data = weather_df.merge(influenza_df, how = 'inner', left_index = True, right_index = True)\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "deletable": false,
    "editable": false,
    "id": "pBLbdkgjrLZo",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b883da0ad1118f1c683f3099a2c2a6f",
     "grade": false,
     "grade_id": "cell-ddb7a1f7f5d45387",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "f046dcb1-b977-4c72-8a28-fc7edd87b9d0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!!\n",
    "data_merged = merge_data(weekly_weather_data, data_influenza)\n",
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "yN7rqDQpuJgm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2b63ce94c8dc67ca2687fe9e92ae138",
     "grade": true,
     "grade_id": "cell-e0d6c1545e449bb1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "7aa3184d-5f15-46fd-8818-95ffef99940a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tests, DO NOT MODIFY OR COPY THIS CELL!!\n",
    "print(data_merged.shape)\n",
    "assert data_merged.shape[0] > 300, \"there should be more than 300 rows in the merged dataset\"\n",
    "assert data_merged.shape[1] >= 14, \"1 column for infections, 13 feature columns from weather data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
